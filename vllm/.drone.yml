kind: pipeline
type: docker
name: build-python-whl-arm64

platform:
  os: linux
  arch: arm64

steps:
  - name: setup-binfmt
    image: tonistiigi/binfmt:latest
    privileged: true
    settings:
      install: true

  - name: build-whl
    image: nvidia/cuda:12.4.1-cudnn-devel-ubuntu22.04
    privileged: true
    settings:
      platform:
        - linux/arm64
    environment:
      DOCKER_PLATFORM: linux/arm64
      DEBIAN_FRONTEND: noninteractive
    commands:
      # Update and install required dependencies
      - apt-get update && apt-get install -y git python3.11 python3.11-venv python3.11-dev python3-pip build-essential curl

      - export VLLM_VERSION=0.6.6.post1
      # Clone the target repository
      - git clone --recursive https://github.com/vllm-project/vllm.git
      - cd vllm
      - git checkout v0.6.6.post1
      - git submodule sync
      - git submodule update --init --recursive

      # Create and activate a Python virtual environment
      - python3.11 -m venv venv
      - . venv/bin/activate

      # ENV
      ## compile PyTorch with new C++ ABI enabled
      - export _GLIBCXX_USE_CXX11_ABI=1
      ## export correct CUDA path if not set (/usr/local/cuda version set by "update-alternatives --config cuda")
      - export CUDA_HOME=/usr/local/cuda
      ## ARM64 opt ld
      ##- export USE_PRIORITIZED_TEXT_FOR_LD=1

      # Upgrade pip and install required tools in the venv
      - pip3 install --upgrade pip setuptools wheel ninja cmake
      - pip3 install https://server.example.com/builds/vision/releases/download/v0.20.1/torchvision-0.20.1-cp311-cp311-linux_aarch64.whl \
        https://server.example.com/builds/pytorch/releases/download/v2.5.1/torch-2.5.1-cp311-cp311-linux_aarch64.whl \
        https://server.example.com/builds/xformers/releases/download/v0.0.28.post3-torch251/xformers-0.0.29+f3bc7a78.d20241231-cp311-cp311-linux_aarch64.whl \
        https://server.example.com/builds/triton/releases/download/v3.1.0/triton-3.1.0-cp311-cp311-linux_aarch64.whl
      - python3.11 use_existing_torch.py
      - pip3 install -r requirements-build.txt
      # Build the .whl file
      - MAX_JOBS=66 python3.11 setup.py bdist_wheel

      # Organize the built .whl files for ARM64
      - mkdir -p ../dist/arm64
      - mv dist/*.whl ../dist/arm64/

  - name: upload-release
    image: plugins/gitea-release
    settings:
      base_url: https://server.example.com
      api_key:
        from_secret: api_token_gitea
      files: dist/arm64/*.whl
      checksum: sha256
      title: "ARM64 Python Wheels with CUDA"
      note: "Automated build using nvidia/cuda:12.4.1-cudnn-devel-ubuntu22.04 for ARM64 architecture."
      draft: false

trigger:
  event:
    - tag

when:
  ref:
    include:
      - refs/tags/*